## Text2ImageGen: Text-to-Image Generation Using Transformer-Based Embeddings and Diffusion Models

- Text2ImageGen is a deep learning project that explores how language and vision models can work together to generate images from natural language descriptions.
- Built as part of IE 7615 â€“ Deep Learning for AI, this project integrates a Transformer-based text encoder (CLIP) with a Diffusion-based image generator (Stable Diffusion/DDPM) to create visually coherent and semantically aligned images from text prompts.
- The work emphasizes multimodal learning, conditional generative modeling, and evaluation of model performance using both quantitative metrics (FID, Inception Score) and qualitative visual analysis.
